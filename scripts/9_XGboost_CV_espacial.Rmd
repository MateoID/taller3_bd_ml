---
title: "XGBoostOPTTESTED"
output: html_document
---

```{r}
# -----------------------------
# 1. LIBRERIAS Y FUNCIONES
# -----------------------------
library(tidyverse)
library(xgboost)
library(Matrix)
library(caret)
library(sf)
library(text2vec)
library(irlba)
library(stopwords)
library(Metrics)
library(FNN)        # Para nearest neighbors (validación espacial)
library(data.table)

# Función de limpieza de texto
clean_text <- function(text) {
  text %>%
    tolower() %>%
    str_replace_all("[^[:alnum:] ]", " ") %>%
    str_squish()
}

# -----------------------------
# 2. CARGA DATOS Y UNIFICACIÓN
# -----------------------------
train <- readRDS("../data/train.rds")
test <- readRDS("../data/test.rds")

train <- st_as_sf(train, coords = c("lon", "lat"), crs = 4326) # Asumimos lon/lat
test <- st_as_sf(test, coords = c("lon", "lat"), crs = 4326)

data <- bind_rows(
  train %>% mutate(dataset = "train"),
  test %>% mutate(dataset = "test")
)

# -----------------------------
# 3. FILTRADO DE OUTLIERS EN TRAIN
# -----------------------------
q_low <- quantile(train$price, 0.005, na.rm = TRUE)
q_high <- quantile(train$price, 0.995, na.rm = TRUE)

data <- data %>%
  filter(dataset == "test" | (price >= q_low & price <= q_high))

data <- data %>%
  mutate(
    ciclorutas_mts = as.numeric(as.character(ciclorutas_mts)),
    avenidas = as.numeric(as.character(avenidas)),
    parque = as.numeric(as.character(parque)),
    invasiones_100m = as.numeric(as.character(invasiones_100m)),
  )

# -----------------------------
# 4. FEATURE ENGINEERING AVANZADO
# -----------------------------
data <- data %>%
  mutate(
    # Limpieza texto
    description_clean = clean_text(description),
    title_clean = clean_text(title),
    full_text = paste(title_clean, description_clean),

    # Variables binarias por keywords en texto
    has_balcon = as.numeric(str_detect(description_clean, "balc|terraza")),
    has_chimenea = as.numeric(str_detect(description_clean, "chimenea")),
    has_gimnasio = as.numeric(str_detect(description_clean, "gimnasio")),
    has_piscina = as.numeric(str_detect(description_clean, "piscina")),
    has_duplex = as.numeric(str_detect(description_clean, "duplex")),

    # Tratamiento superficie
    surface_total = ifelse(surface_total > 500, NA, surface_total),
    surface_total = ifelse(is.na(surface_total), median(surface_total, na.rm = TRUE), surface_total),

    # Variables densidad y ratios
    rooms_density = rooms / (surface_total + 1),
    covered_ratio = surface_covered / (surface_total + 1),
    surface_covered_ratio = surface_covered / surface_total,
    rooms_per_bathroom = rooms / (bathrooms + 1),

    # Antigüedad (con manejo robusto)
    year_built = ifelse(is.na(year) | year < 1800 | year > 2023, NA, year),
    years_since_construction = ifelse(is.na(year_built), median(2023 - year_built, na.rm = TRUE), 2023 - year_built),

    # Suma de scores
    transport_score = sitp_100m + tm_mts,
    environment_score = ciclorutas_mts + avenidas + parque + invasiones_100m,

    # Precio por m2 (solo para train)
    price_per_m2 = ifelse(dataset == "train", price / surface_total, NA),

    # Localidad como factor agrupado
    localidad_fct = fct_lump_n(as.factor(localidad), n = 15)
  )

# -----------------------------
# 5. FEATURE ESPACIALES ADICIONALES
# -----------------------------
# Transformar coordenadas a CRS métricos para cálculos
data <- st_transform(data, crs = 3857)

coords <- st_coordinates(data)

data <- data %>%
  mutate(
    x_coord = coords[,1],
    y_coord = coords[,2]
  )

# Distancia mínima a centro de la ciudad (asumiendo coordenada central)
city_center <- st_sfc(st_point(c(mean(data$x_coord), mean(data$y_coord))), crs = 3857)
data$dist_to_center <- as.numeric(st_distance(data, city_center))

# Distancias a puntos clave
lugares_clave <- tibble::tibble(
  nombre = c("Zona T", "Usaquén", "Aeropuerto El Dorado", "Centro Internacional"),
  lon = c(-74.0571, -74.0368, -74.1468, -74.0665),
  lat = c(4.6668, 4.6920, 4.7016, 4.6097)
) %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%
  st_transform(3857)

for (i in 1:nrow(lugares_clave)) {
  nombre <- gsub(" ", "_", tolower(lugares_clave$nombre[i]))
  data[[paste0("dist_", nombre)]] <- as.numeric(st_distance(data, lugares_clave[i, ]))
}

# ===============================
# 3. VARIABLES DERIVADAS
# ===============================
data <- data %>%
  mutate(
    rooms_per_bathroom = ifelse(bathrooms > 0, rooms / bathrooms, NA),
    area_per_room = ifelse(rooms > 0, surface_total / rooms, NA),
    area_per_bathroom = ifelse(bathrooms > 0, surface_total / bathrooms, NA),
    price_per_sqm = price / surface_total,
    total_rooms = rooms + bathrooms,
    log_area = log1p(surface_total),
    log_price_per_sqm = log1p(price_per_sqm)
  )

# ===============================
# 4. PROMEDIOS POR LOCALIDAD
# ===============================
data <- data %>%
  mutate(localidad_fct = as.factor(localidad))

# Solo usa train para calcular los promedios
mean_price_by_localidad_train <- data %>%
  filter(dataset == "train") %>%
  group_by(localidad_fct) %>%
  summarise(mean_price_localidad = mean(price, na.rm = TRUE)) %>%
  st_drop_geometry()  # Quita geometría para que `left_join` funcione correctamente


data <- data %>%
  left_join(mean_price_by_localidad_train, by = "localidad_fct")

```

```{r}
# -----------------------------
# 6. PROCESAMIENTO AVANZADO DE TEXTO (TF-IDF + PCA)
# -----------------------------
it <- itoken(data$description_clean, progressbar = FALSE)
vocab <- create_vocabulary(it, stopwords = stopwords("es")) %>%
  prune_vocabulary(term_count_min = 5)
vectorizer <- vocab_vectorizer(vocab)
dtm <- create_dtm(it, vectorizer)

tfidf <- TfIdf$new()
dtm_tfidf <- tfidf$fit_transform(dtm)

# PCA para reducir dimensionalidad
tfidf_pca <- prcomp_irlba(dtm_tfidf, n = 50)
X_text_pca <- as.data.frame(tfidf_pca$x)
colnames(X_text_pca) <- paste0("text_pca_", seq_len(ncol(X_text_pca)))

# Unir componentes PCA al dataset
data <- data %>%
  select(-starts_with("text_pca_")) %>%
  bind_cols(X_text_pca)
```


```{r}
# -----------------------------
# 7. DEFINIR FEATURES PARA MODELADO
# -----------------------------

data <- data %>%
  mutate(
    x_coord = st_coordinates(.)[,1],
    y_coord = st_coordinates(.)[,2]
  )

features <- c(
  "surface_total", "rooms", "bedrooms", "bathrooms", "parqueaderos",
  "has_balcon", "has_chimenea", "has_gimnasio", "has_piscina", "has_duplex",
  "years_since_construction", "rooms_density", "covered_ratio",
  "transport_score", "environment_score", "dist_to_center",
  paste0("text_pca_", 1:50),
  paste0("dist_", gsub(" ", "_", tolower(lugares_clave$nombre))),"rooms_per_bathroom", "area_per_room", "area_per_bathroom", "total_rooms", "log_area", "mean_price_localidad"
)

# -----------------------------
# 8. PREPARAR DATOS PARA MODELADO
# -----------------------------
train_clean <- data %>%
  filter(dataset == "train") %>%
  st_drop_geometry() %>%
  mutate(price_millions = price / 1e6) %>%
  select(all_of(features), localidad_fct, price_millions, x_coord, y_coord) %>%
  drop_na(price_millions)

test_clean <- data %>%
  filter(dataset == "test") %>%
  st_drop_geometry() %>%
  select(all_of(features), localidad_fct, property_id, x_coord, y_coord)
```

```{r}
# -----------------------------
# 9. PREPROCESAMIENTO NUMERICO + ONE HOT ENCODING
# -----------------------------
preproc <- preProcess(train_clean[, features], method = c("medianImpute", "center", "scale", "YeoJohnson"))
X_train <- predict(preproc, train_clean[, features])
X_test <- predict(preproc, test_clean[, features])

# Dummies para localidad
dummies <- dummyVars(~ localidad_fct, data = train_clean)
X_train <- cbind(X_train, predict(dummies, train_clean))
X_test <- cbind(X_test, predict(dummies, test_clean))

# Convertir a numeric después de bind
X_train <- data.frame(lapply(X_train, as.numeric))
X_test <- data.frame(lapply(X_test, as.numeric))

# Matrices para xgboost
X_train_matrix <- as.matrix(X_train)
X_test_matrix <- as.matrix(X_test)

stopifnot(nrow(X_train_matrix) == nrow(train_clean))

dtrain <- xgb.DMatrix(data = X_train_matrix, label = log1p(train_clean$price_millions))
dtest <- xgb.DMatrix(data = X_test_matrix)

# -----------------------------
# 10. VALIDACION ESPACIAL (K-FOLD POR PROXIMIDAD)
# -----------------------------
# Usamos clustering por coordenadas para definir folds

coords_train <- as.matrix(train_clean %>% select(x_coord, y_coord))

# 4. Imputar NA si existen en coords_train (poco probable, pero por si acaso)
if(any(is.na(coords_train))) {
  coords_train[is.na(coords_train)] <- median(coords_train, na.rm = TRUE)
}

set.seed(123)
kfolds <- 3
coords_train <- as.matrix(train_clean %>% select(x_coord = "x_coord", y_coord = "y_coord"))
if (any(is.na(coords_train))) coords_train[is.na(coords_train)] <- median(coords_train, na.rm=TRUE)
km <- kmeans(coords_train, centers = kfolds, nstart = 25)
fold_ids <- km$cluster
```

```{r}
# -----------------------------
# 11. PARAMETROS XGBOOST OPTIMIZADOS
# -----------------------------
params <- list(
  booster = "gbtree",
  eta = 0.01,
  max_depth = 4,
  subsample = 0.85,
  colsample_bytree = 0.8,
  min_child_weight = 5,
  gamma = 5,
  lambda = 1,
  alpha = 0.5,
  objective = "reg:squarederror",
  eval_metric = "mae"
)

# -----------------------------
# 12. CROSS-VALIDATION ESPACIAL MANUAL
# -----------------------------
mae_fold <- c()
rmse_fold <- c()

for(i in 1:kfolds) {
  cat("Fold", i, "\n")
  
  val_idx <- which(fold_ids == i)
  train_idx <- setdiff(seq_len(nrow(X_train_matrix)), val_idx)
  
  dtrain_cv <- xgb.DMatrix(data = X_train_matrix[train_idx, ], label = log1p(train_clean$price_millions[train_idx]))
  dval_cv <- xgb.DMatrix(data = X_train_matrix[val_idx, ])
  y_val <- train_clean$price_millions[val_idx] * 1e6
  
  model_cv <- xgb.train(
    params = params,
    data = dtrain_cv,
    nrounds = 2000,
    early_stopping_rounds = 50,
    watchlist = list(train = dtrain_cv),
    verbose = 0
  )
  
  pred_log <- predict(model_cv, dval_cv)
  pred_price <- expm1(pred_log) * 1e6
  
  mae <- mean(abs(pred_price - y_val))
  rmse <- sqrt(mean((pred_price - y_val)^2))
  
  cat(sprintf("MAE: %0.0f, RMSE: %0.0f\n", mae, rmse))
  
  mae_fold <- c(mae_fold, mae)
  rmse_fold <- c(rmse_fold, rmse)
}

cat(sprintf("\nPromedio MAE CV: %0.0f ± %0.0f\n", mean(mae_fold), sd(mae_fold)))
cat(sprintf("Promedio RMSE CV: %0.0f ± %0.0f\n", mean(rmse_fold), sd(rmse_fold)))
```

```{r}
# -----------------------------
# 13. ENTRENAMIENTO FINAL CON EARLY STOPPING
# -----------------------------
final_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 2200,
  watchlist = list(train = dtrain),
  early_stopping_rounds = 50,
  verbose = 1
)

# -----------------------------
# 14. PREDICCION Y POST-PROCESAMIENTO
# -----------------------------
pred_log <- predict(final_model, dtest)
pred_price <- expm1(pred_log) * 1e6  # Esto es muy importante

# Corrección post-predicción: límite inferior (precio no negativo)
#pred_test_price <- pmax(pred_test_price, 100000) +

submission <- data.frame(
  property_id = test_clean$property_id,
  price = pred_price
)

write_csv(submission, "submission_final_mae_optimized_Spatial_LugaresCercanos_Real.csv")

# -----------------------------
# 15. EVALUACION FINAL SOBRE TRAIN
# -----------------------------
pred_train_log <- predict(final_model, dtrain)
pred_train_price <- expm1(pred_train_log) * 1e6
real_price <- train_clean$price_millions * 1e6

rmse_log <- sqrt(mean((pred_train_log - log1p(train_clean$price_millions))^2))
rmse_real <- sqrt(mean((pred_train_price - real_price)^2))
mae_log <- mean(abs(pred_train_log - log1p(train_clean$price_millions)))
mae_real <- mean(abs(pred_train_price - real_price))

cat("\n===== EVALUACION EN TRAIN SET =====\n")
cat("RMSE log1p(price):", round(rmse_log, 4), "\n")
cat("RMSE price real (COP):", format(round(rmse_real, 0), big.mark = ","), "\n")
cat("MAE log1p(price):", round(mae_log, 4), "\n")
cat("MAE price real (COP):", format(round(mae_real, 0), big.mark = ","), "\n")
```

