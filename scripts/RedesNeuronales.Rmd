
```{r}
# rutas relativas
raw_data_path <- '../data'
predictions_path <- '../results/predictions'
db_train <- readRDS(file.path(raw_data_path, 'train.rds'))
db_test <- readRDS(file.path(raw_data_path, 'test.rds'))

# Verificando la estructura de la base de datos 
# str(db_train)  
# head(db_train)
# summary(db_train)

#Modificando variables relevantes 
db_train$property_type <- as.factor(db_train$property_type)
db_train$localidad <- as.factor(db_train$localidad)
db_train$upl <- as.factor(db_train$upl)
```


```{r}
# librerias
library(tidyverse)
library(sf)
library(caret)
library(xgboost)
library(randomForest)
library(glmnet)
library(SuperLearner)
library(tidytext)
library(tm)
library(osmdata)
library(tmap)
library(text2vec)
library(irlba)
library(tensorflow)
library(keras)



```


```{r}
# -----------------------------
# UNIFICAR Y PREPROCESAR
# -----------------------------
clean_text <- function(text) {
  text %>%
    tolower() %>%
    str_replace_all("[^[:alnum:] ]", " ") %>%
    str_squish()
}

data <- bind_rows(
  db_train %>% dplyr::mutate(dataset = "train"),
  db_test %>% dplyr::mutate(dataset = "test")
)

# -----------------------------
# SEPARAR TRAIN Y TEST
# -----------------------------
features <- c("surface_total", "rooms", "bedrooms", "bathrooms", "parqueaderos",
              "has_balcon", "has_chimenea", "has_gimnasio", "has_piscina", "has_duplex",
              "years_since_construction", "rooms_density", "covered_ratio",
              "transport_score", "environment_score",
              paste0("text_pca_", 1:50))

train_clean_full <- data %>%
  filter(dataset == "train") %>%
  sf::st_drop_geometry() %>% # Usar sf::st_drop_geometry si st_drop_geometry no está cargado
  select(all_of(features), localidad_fct, price_millions) %>%
  drop_na(price_millions) # Asegura que la variable respuesta no tenga NA

test_clean_kaggle <- data %>%
  filter(dataset == "test") %>%
  sf::st_drop_geometry() %>% # Usar sf::st_drop_geometry
  select(all_of(features), localidad_fct, property_id)

# ------------------------------------------------
# SEPARAR TRAIN ORIGINAL EN TRAIN Y TEST INTERNAS 
# ------------------------------------------------
# Paso 2.1: Particionar train_clean_full para evaluación interna
set.seed(42) # Para reproducibilidad
index_train_internal <- createDataPartition(
  y = train_clean_full$price_millions,
  p = 0.8, # 80% para entrenamiento interno, 20% para prueba interna
  list = FALSE
)

train_internal <- train_clean_full[index_train_internal, ]
test_internal <- train_clean_full[-index_train_internal, ]

# Separar la variable respuesta para el conjunto de prueba interno
y_train_internal <- train_internal$price_millions
y_test_internal_real <- test_internal$price_millions

```


```{r}
# Paso 3.1: Asegurarse de que localidad_fct no tenga NA explícitos en todos los conjuntos
train_internal$localidad_fct <- fct_explicit_na(train_internal$localidad_fct, na_level = "missing")
test_internal$localidad_fct <- fct_explicit_na(test_internal$localidad_fct, na_level = "missing")
test_clean_kaggle$localidad_fct <- fct_explicit_na(test_clean_kaggle$localidad_fct, na_level = "missing")


# Paso 3.2: Imputación + normalización de variables numéricas (ajustado en train_internal)
preproc <- preProcess(train_internal[, features], method = c("medianImpute", "center", "scale", "YeoJohnson"))

# Aplicar transformación a los conjuntos internos
X_train_internal_processed <- predict(preproc, train_internal[, features])
X_test_internal_processed <- predict(preproc, test_internal[, features])

# Aplicar transformación al conjunto de Kaggle
X_test_kaggle_processed <- predict(preproc, test_clean_kaggle[, features])


# Paso 3.3: Asegurando que 'parqueaderos' sea numérica (después de preProcess)
# Aunque preProcess debería manejar esto, esta línea refuerza la intención.
# Si parkeaderos fue imputado, ya será numérico.
X_train_internal_processed$parqueaderos <- as.numeric(X_train_internal_processed$parqueaderos)
X_test_internal_processed$parqueaderos <- as.numeric(X_test_internal_processed$parqueaderos)
X_test_kaggle_processed$parqueaderos <- as.numeric(X_test_kaggle_processed$parqueaderos)


# Paso 3.4: One-hot encoding de localidad (ajustado en train_internal)
# Es crucial que los niveles de los factores sean los mismos entre train y test.
# dummyVars automáticamente maneja los niveles que solo aparecen en test o en train.
dummies <- dummyVars(~ localidad_fct, data = train_internal) # Ajustar dummies en train_internal

X_train_dummies_internal <- predict(dummies, train_internal)
X_test_dummies_internal <- predict(dummies, test_internal)
X_test_dummies_kaggle <- predict(dummies, test_clean_kaggle)


# Paso 3.5: Unión final y conversión a matrices
X_train_mat <- as.matrix(cbind(X_train_internal_processed, X_train_dummies_internal))
X_test_mat_internal <- as.matrix(cbind(X_test_internal_processed, X_test_dummies_internal))
X_test_mat_kaggle <- as.matrix(cbind(X_test_kaggle_processed, X_test_dummies_kaggle))

# Verificación de NAs en las matrices finales
cat("NA en X_train_mat:", anyNA(X_train_mat), "\n")
cat("NA en X_test_mat_internal:", anyNA(X_test_mat_internal), "\n")
cat("NA en X_test_mat_kaggle:", anyNA(X_test_mat_kaggle), "\n")
```

```{r }

# Definir el modelo
model <- keras_model_sequential() %>%
  layer_dense(units = 128, activation = "relu", input_shape = c(ncol(X_train_mat))) %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = 1)

# Compilar el modelo
model %>% compile(
  loss = "mse",
  optimizer = optimizer_adam(),
  metrics = list("mean_absolute_error")
)

# Resumen
summary(model)

# Entrenamiento
history <- model %>% keras::fit(
  x = X_train_mat,
  y = y_train_internal,
  epochs = 10, # Aumente las épocas para permitir que Early Stopping actúe
  batch_size = 32,
  validation_split = 0.2, # Este validation_split se aplica SOBRE X_train_mat
  callbacks = list(callback_early_stopping(monitor = "val_loss", patience = 10, restore_best_weights = TRUE)),
  verbose = 2
)



```

```{r}
# Sacando el MAE y el RMSE usando un set de validación sacado del df de train original 
# Predecir en el conjunto de test interno
y_test_internal_pred <- model %>% predict(X_test_mat_internal) %>% as.vector()

# Calcular métricas
mae_internal <- mean(abs(y_test_internal_pred - y_test_internal_real))
rmse_internal <- sqrt(mean((y_test_internal_pred - y_test_internal_real)^2))

cat("MAE (test interno):", mae_internal, "\n")
cat("RMSE (test interno):", rmse_internal, "\n")
```
```{r}
# Predecir en el conjunto de test de Kaggle
y_test_kaggle_pred <- model %>% predict(X_test_mat_kaggle) %>% as.vector()

# Crear dataframe con las predicciones (asumiendo que test_clean_kaggle tiene property_id)
submission <- data.frame(
  property_id = test_clean_kaggle$property_id,
  price_millions = y_test_kaggle_pred
)

# Guardar las predicciones (opcional)
write.csv(submission, file.path(predictions_path,"predictions_redes_neuronales.csv"), row.names = FALSE)
```
